---
title: 'Redefining association: Calculating simple ratio'
author: 'William Cioffi and Christin Khan'
date: '`r format(Sys.time(), "%Y-%m-%d %H:%M:%S %Z")`'
output:
  html_document:
    highlight: pygments
    number_sections: true
    toc: true
    toc_float:
      collapsed: false
bibliography: biblio.bib
csl: journal-of-mammalogy.csl
link-citations: true
---

# Calculate simple ratio association indices

We decided on the simple ratio association index [@cairns1987] because it had the fewest assumptions of the commonly used association indices [for more discussion see @hoppitt2018]. This index is defined as:

$$\frac{x}{x + y_{ab} + y_a + y_b}$$

where $x$ is the total number of sightings where animal $A$ and $B$ are located together, $y_{ab}$ is the number of sightings in which animals $A$ and $B$ are both located apart, $y_a$ and $y_b$ are the number of sightings in which only $A$ or only $B$ is located respectively.

We used a set of custom functions to calculate the simple ratio for this dataset with the following restrictions.

- Each age sex class for a particular real individual was considered a separate id for the purposes of this model.
- Each day was considered a sampling period.
- Two animals were considered associated if they were within a certain time-distance threshold.
- Only animals with at least 35 total sightings were considered.
- Only dyads that overlapped in the database for at least 1 day were considered.

## Time-distance threshold

Our goal was to score dyads as associated if they were within a critical distance $d_c$ of each other. Since all animals are not sampled simulatenously we considered a conservative time-distance threshold where we calculated how far the animals might have separated during the time interval between sightings based on an average swim speed $\bar{u}$. We calculated relative velocity as $u_{rel} = 2 \cdot \bar{u}$. Of course, animals might also move closer together during this time, but we decided to be conservative in assigning associations. That is, in this model we minimized the chance that dyads were scored as associated when they had not been in truth within $d_c$ of each other, while increasing the likelyhood that animals that were in truth within $d_c$ of each other were not scored as associated. 

If animals $A$ and $B$ were sighted at $t_a$ and $t_b$ times with a relative velocity away from each other of $u_{rel}$ then we considered a dyad associated if

$$u_{rel} \cdot ||t_a - t_b|| \le d_c$$
 
We decided on:

- $d_c = {0.03, 1, 5, 10, 15, 20}$ kilometers
- $\bar{u} = 3.1$ kilometers per hour, based on literature review.

## Overlap threshold

As mentioned above we considered only dyads that overlapped at least 1 day in the database. Another way to concieve of this was that the dyads were available to associate with each other for at least 1 day even if they never did. Note that this threshold produces slightly different effects for different age sex classes. In particular, age classes that animals spend less time in (juvenile and lactating) would have more difficulty (and not necessarily uniform) meeting this threshold with other dyads.

## Set up

An implementation of the haversine formula.

```{r}
torad <- function(ang) {
	radians <- ang*pi/180
	return(radians)
}

# haversine
latlond <- function(lat1, lon1, lat2, lon2) {
	R <- 6371 # radius of the earth in km

	dlat <- torad(lat2) - torad(lat1)
	dlon <- torad(lon2) - torad(lon1)

	a = sin(dlat/2) * sin(dlat/2) + cos(torad(lat1)) * cos(torad(lat2)) * sin(dlon/2) * sin(dlon/2)
	c = 2 * atan2(sqrt(a), sqrt(1-a))

	d = R * c

	return(d)
}
```

These helper functions are for `outer` to return the difference in time and distance between a dyad.

```{r}
# distance functions
source("associationfunctions/distance.R")

pairdistances <- function(n, p) {
	lat1 <- dat[n, 'Latitude']
	lon1 <- dat[n, 'Longitude']
	lat2 <- dat[p, 'Latitude']
	lon2 <- dat[p, 'Longitude']
				
	dists <- latlond(lat1, lon1, lat2, lon2)
	
	return(dists)
}

timedifferences <- function(n, p) {
	timedif <- dateswithtimes[p] - dateswithtimes[n]
	timedif.hours <- abs(as.numeric(timedif, units = "hours"))
	return(timedif.hours)
}
```

Set some initial values:

```{r}
max_assoc_distance <- 10 # km
numsampcutoff <- 35
overlapdaycutoff <- 1 # day
relative_speed_km_per_hour <- 3.1 * 2 # 3.1 kph * 2 whales diametrically opposed
```

Load in the raw data.

```{r}
load("data/agesex_assigned.RData")
load("data/nax_avail.RData")
```

Remove any sightings of dead animals, or those missing lat or lon from `dat`. As in other fields, it appears that a Latitude or Longitude of `0` indicates `NA` even though `0` could be a valid value. Dead animals are identified from the behavior codes.

```{r remove-na-and-dead}
missing_lat_or_lon <- (dat$Latitude == 0 | dat$Longitude == 0)
dat <- dat[!missing_lat_or_lon, ]

sightings_of_dead_whales <- grepl("DEAD", toupper(dat$Behaviors))
dat <- dat[!sightings_of_dead_whales, ]
```

Calculate dates. We're only going to use entries with times, because we have used time in our association index calculation. Instead of `0` meaning midnight. I think in this context it means `NA`.

```{r calculatedate}
# if there is a missing value in any of these fields we won't use it
missing_date_or_time <- (is.na(dat$date) | dat$Time == 0)

# remove these rows from dat
dat <- dat[!missing_date_or_time, ]

# format for hhmm and split into hh and mm
time_char <- sprintf("%04d", dat$Time)
time_hrs <- substring(time_char, 1, 2)
time_min <- substring(time_char, 3, 4)

dateswithtimes <- paste0(dat$date, " ", time_hrs, ":", time_min)
dateswithtimes <- as.POSIXct(dateswithtimes, format = "%Y-%m-%d %H:%M", tz = "UTC")

dates <- as.Date(dat$date, tz = "UTC")
udates <- unique(dates)
```

Set up the ids and `nsamp` which will be the number of sampling periods (days in this case).
```{r}
uids 	<- sort(unique(dat$agesexid))
nids 	<- length(uids)
nsamp 	<- length(udates)
```

There were some ids that were never observed with times (even though there was a good date). So we can remove those here, since we can't calculate our association index without a time.

```{r remove-never-timed}
removedese <- -which(!(rownames(nax_avail) %in% uids))
nax_avail <- nax_avail[removedese, ]

# check to make sure everything lines up
all(rownames(nax_avail) == uids)
```

Make some blank matrices to hold results:

-  `assoc` nid x nid matrix of the number of sampling periods any two ids were associated
-  `nax` nid x n(sampling period) binary matrix where 1 = seen in that sampling period and 0 = not seen

```{r}
assoc 	<- matrix(0, nids, nids, dimnames = list(uids, uids))
nax 	  <- matrix(0, nids, nsamp, dimnames = list(uids, as.character(udates)))
```

## Calculate associations (numerator)
First we'll calculate associations and save it to `assoc` which will be the start of `x` in the Cairns and Schwager notation. While we're doing this we can also calculate `nax` (the sighting matrix) which we'll need later on to help calculate the denominator of the association index.

Here is the first megaloop:

-  go through sampling period by sampling period.
-  grab the ids
-  calculate distances
-  calculate time differences
-  assign associations
-  increment

```{r}
for(i in 1:nsamp) {
  # these rows (individuals) were observed on the current sampling day
  samp <- which(dates == udates[i])
	
  # get the ids for the individuals sampled on that day and increment nax
	curids <- dat[samp,]$agesexid
	nax[match(curids, uids), i] <- 1
  
	# calculate the pairwise distance between all individauls sighted that day
	dists <- outer(samp,samp, FUN = pairdistances)
	diag(dists) <- NA

	# calculate the pairwise time difference between all individuals sighted that day
	timediffs <- outer(samp, samp, FUN = timedifferences)
	diag(timediffs) <- NA

	# calculate the association threshold and which dyads meet it
	new_dists <- dists + (relative_speed_km_per_hour * timediffs)
	close_enough <- which(new_dists <= max_assoc_distance, arr.ind = TRUE)

	# if any dayds were close enough in spacetime to be associated
	# then increment assoc (= x in cairns and schwager notation)
	if(nrow(close_enough) > 0) {
		a <- match(dat$agesexid[samp[close_enough[,1]]], uids)
		b <- match(dat$agesexid[samp[close_enough[,2]]], uids)
	  
		# is this condition ever met?
		kill <- which(a == b)
		if(length(kill) > 0) {
			a <- a[-kill]
			b <- b[-kill]
		}
		
		# goods just calculates the right cell in the matrix for each of the dyads
		goods <- unique(c((b-1)*nids + a))
		assoc[goods] <- assoc[goods] + 1
		}
}
```

## Calculate denominator
Now we're going to calculate the pieces needed for the denominator of the simple ratio. I'll use two concepts from SOCPROG: `nmatrix` and `yab_prime`, which are relatively easy to calculate with some simple linear algebra.

The `nmatrix` is an nid x nid matrix with the number of times both animals in a dyad were observed. In other words, it should be $2x + 2y_{ab} + y_a + y_b$.

`yab_prime` is an nid x nid matrix is equal to the transpose crossproduct of `nax`. Or in other words, it should be $x + y_{ab}$.

So to get the denominator we can simply do:

$nmatrix - yabprime$

which is equal to:

$2x + 2y{ab} + y_a + y_b - y_{ab} - x$

and which simplifies to the desired denominator:

$x + y_{ab} + y_a + y_b$

First, we'll set up some matrices.

```{r}
nmatrix 	<- matrix(0, nids, nids, dimnames = list(uids, uids))
yab_prime 	<- matrix(0, nids, nids, dimnames = list(uids, uids))
```

As elluded to above, we're going to keep track of availability of individuals (those that were alive at the same time). To do that we'll calculate overlap which is just the transpose crossproduct of `nax_avail`.

```{r}
overlap <- tcrossprod(nax_avail)
diag(overlap) <- NA
overlapping <- which(overlap >= overlapdaycutoff, arr.ind = TRUE)
```

And we'll limit our calculations to those dyads that meet our overlap cutoff. In addition, we'll make sure that we're calculating `nmatrix` and `yab_prime` only for those time periods of overlap.

So here's the second megaloop:

-  grab the dyads
-  find their sampling periods of overlap
-  calculate yab_prime and nmatrix for this period of overlap

**This is the slowest loop in this whole process and there is probably a more efficient way to write this, but it works for now.**

```{r, eval = FALSE}
# eval = FALSE

pb <- txtProgressBar(style = 3)
for(i in 1:nrow(overlapping)) {
if((i %% 100) == 0) setTxtProgressBar(pb, i / nrow(overlapping))
  # grab the dyads one by one
  a <- overlapping[i, 1]
  b <- overlapping[i, 2]
  
  # just subsetting the nax and nax_avail for this dyad
  nax_avail_tmp <- nax_avail[c(a, b), ]
  
  # get the days on which they were both alive
  samps_tmp <- colnames(nax_avail_tmp)[colSums(nax_avail_tmp) == 2]
  
  # get those days on which there were any sightings and they were both alive
  samps_tmp <- intersect(samps_tmp, colnames(nax))
  
  # get the nax for just these samples
  nax_tmp <- nax[c(a, b), samps_tmp, drop = FALSE]
  
  # calculate yab_prime
  yab_prime_tmp <- tcrossprod(nax_tmp)
  yab_prime[c(a, b), c(a, b)] <- yab_prime_tmp
  
  # calculate nmatrix
  nsight_tmp <- rowSums(nax_tmp)
  nmatrix_tmp <- outer(nsight_tmp, nsight_tmp, '+')
  nmatrix[c(a, b), c(a, b)] <- nmatrix_tmp
}
close(pb)

# save these outputs because they took a long time
save(assoc, yab_prime, nmatrix, dat, file = "data/simple_ratio_calc.RData")
```


Now we can actually calculate the simple ratio and do some filtering.

```{r simple-ratio}
# load in the results if not rerunning
load("data/simple_ratio_calc.RData")

sr <- assoc / (nmatrix - yab_prime)

# The diagonal isn't that meaningful here
diag(sr) <- NA
```

Ready to filter a little bit:

-  calculate and apply numsampcutoff
-  If dyads weren't alive for long enough to make the cut let's make their association index NA not 0.
-  We can now remove any individuals that has a NA with every other dyad.
-  If a dyad passes all these and still was never seen together than it should really be a 0 not an NA. This doesn't turn out to happen for any of the ids here.

```{r calc-numsamp-cutoff}
# nsightings by agesexid
nsightings <- rowSums(nax)

# egno (cross agesexid)
egno <- substring(names(nsightings), 1, 4)

# dataframe pasting everything together
nsightings_df <- data.frame(agesexid = names(nsightings), egno = egno, nsight_agesex = nsightings, stringsAsFactors = FALSE)

# aggregate and match back in
nsight_total <- aggregate(nsight_agesex ~ egno, data = nsightings_df, FUN = sum)
nsightings_df[, 'nsight_total'] <- nsight_total$nsight_agesex[match(nsightings_df$egno, nsight_total$egno)]
```

```{r filter}
# set all the never associates to zero first and then deal with the NAs
sr[assoc == 0] <- 0
diag(sr) <- NA

# apply numsampcutoff
enoughsamps <- nsightings_df$nsight_total >= numsampcutoff
sr[!enoughsamps, !enoughsamps] <- NA

# save this for later calculations
sr.nodayfilt <- sr

# not enough overlap
notenoughoverlap <- overlap <= overlapdaycutoff
sr[notenoughoverlap] <- NA

# remove individuals completely if they never even had the opportunity to associate with anyone
isallna <- apply(sr, 2, function(r) all(is.na(r)))
sr <- sr[!isallna, !isallna]
```

## Calculate Sample Sizes

```{r calc-sample-sizes}
fids <- rownames(sr)

# total combinations
length(fids) #1006

# unique individuals
length(unique(substring(fids, 1, 4))) #613

# agesex class
table(substring(fids, 5, 6))

# sex
table(substring(fids, 6, 6))
```


## Export the Matrix
```{r export-matrix}
write.table(sr, 'matrix.csv', sep=',')
```

## LEMMA: take a look at different overlap days thresholds. 

Look at 1-700 by 10 and plot the percentage that get filtered out. Note that more than half of the dyads overlap 0 days. You can see the big jump at the year because a lot of the catagorization happens at the yearly scale.

```{r lemma-how-filtering-matters}

cutoff <- seq(0, 700, by = 10)[-1]
filtered_perc <- vector(mode = "numeric", length = length(cutoff))
for(i in 1:length(cutoff))
  filtered_perc[i] <- 100* (1- (length(which(overlap >= cutoff[i])) / length(overlap)))

plot(cutoff, filtered_perc,
  las = 1,
  pch = 3,
  xlab = "Mininum number of days overlapping",
  ylab = "percentage of dayds filtered"
)
legend("topleft", legend = "n = 1498176 dyads", bty = 'n')

agesexcount <- list()
# check different overlaps
for(i in 1:length(cutoff)) {
  # not enough overlap
  sr.tmp <- sr.nodayfilt
  notenoughoverlap <- overlap <= cutoff[i]
  sr.tmp[notenoughoverlap] <- NA

  # remove individuals completely if they never even had the opportunity to associate with anyone
  isallna <- apply(sr.tmp, 2, function(r) all(is.na(r)))
  sr.tmp <- sr.tmp[!isallna, !isallna]
  
  fids <- rownames(sr.tmp)
  agesexcount[[i]] <- table(substring(fids, 5, 6))
}

agesexcount <- do.call('rbind', agesexcount)

plot(cutoff, c(range(agesexcount), rep(min(agesexcount), length(cutoff)-2)), type = 'n', las = 1, xlab = "min number of days overlapping", ylab = 'count included')
for(i in 1:ncol(agesexcount)) {
  lines(cutoff, agesexcount[, i], col = i)
}
legend("bottomleft", legend = colnames(agesexcount), col = 1:ncol(agesexcount), lty = 1, bty = 'n')
```

# References
